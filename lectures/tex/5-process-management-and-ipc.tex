\documentclass[10pt,a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[scaled]{helvet}
\usepackage{cite}
\usepackage{url}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
 
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{ %
  language=Octave,                % the language of the code
  basicstyle=\footnotesize,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line 
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},      % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=true,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=none,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  keywordstyle=\color{blue},          % keyword style
  commentstyle=\color{dkgreen},       % comment style
  stringstyle=\color{mauve},         % string literal style
  escapeinside={\%*}{*)},            % if you want to add LaTeX within your code
  morekeywords={*,...}               % if you want to add more keywords to the set
}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{lastpage}
\setlength{\parindent}{0cm}
\floatstyle{boxed} 
\restylefloat{figure}
\renewcommand*\familydefault{\sfdefault}
\title{Process Management and IPC}
\author{David Lynch - david.lynch@raglansoftware.com }
\begin{document}
\maketitle
\begin{abstract}
It is important for any programmer to understand the process life-cycle, and in particular to ensure that any applications that are written correctly leverage these functions. Your applications should  provider clear entry and exit points. When modularizing function into separate components, how these processes communicate also becomes a very important tool in the armoury. This article will examine process management and inter-process communication, or IPC, in detail.
\end{abstract}
\section{Process Management}
A {\bf process} is an active entity of work in a computer system. A process will consist of some code, or more formally a {\bf text-section}. There are a number of things that the operating system will store that are associated with each process. Firstly, a copy of the {\bf program counter} and {\bf CPU} register file is necessarily kept. When the process is context switched, in order to resume from the exact location we left off, we must restore these. Another important entity associated with a process is its {\bf stack}. This can be thought of as a region of memory that contains state that is typically local to the function or method that is currently executing. Function parameters, local variables and return variables are all kept on the stack, and this stack will typically be multiple layers deep. The depth depends on how many seperate function calls have not yet returned in any particular process. Separate to the process stack we have {\bf heap memory}. This memory is a region that is usable by a process, but is dynamically allocated at runtime by the application and the operating system.
\subsection{State}
Speaking generally, a process can be any number of five states. Different operating systems will have different states, usually reflecting things like priority, but each can be distilled as follows. 
\begin{itemize}
\item New - The Process is undergoing creation.
\item Running - Instructions are being executed.
\item Waiting - The process is stalled waiting for some event.
\item Terminated - The process has finished execution.
\end{itemize}
One process may run on one processor at any one time, while many processes can be in the ready and waiting states. 
\begin{figure}
\caption{The Process State Life-Cycle \cite{OSCONCEPTS}}
\begin{center}
\includegraphics[scale=0.75]{../images/process-state.png}
\label{procstate}
\end{center}
\end{figure}
Processes will run through a five stage life-cycle that is illustrated in figure \ref{procstate}. 
\subsection{Process Control Block}
Frequently referred to as the PCB, the process control block is an explicit collection of all the important data that surrounds the management of a process. The following data is is captured in the process control block. 
\newline\newline
{\bf Process state} determines which stage of the life-cycle the process is currently in. The {\bf program counter} is the address register that points to the next instruction that should be executed in the process. {\bf Register state} includes information, such as partial results of programs, and stack pointers. {\bf CPU Schedule Information} includes most importantly the priority of the process. Some more complex information may also be recorded here, in particular how long the process has been running, and or how long the process has be in its current state without gaining control of the CPU.  {\bf Memory management information} associated with this section includes the contents of segment registers, or page tables. This information assists in mapping memory locations on the heap with the process. Also, virtual memory page tables are maintained for the parts of the process that have not yet been loaded from disk. {\bf Accounting information} tracks data such as the ID of the process, which CPU is been used, and for how long.
\section{Process Scheduling}
The objective of {\bf multi-programming} is to have some process executing on the CPU at all times. The {\bf process scheduler} selects an available process based on some criteria. The {\bf job queue} consists of all processes in the system. This is a broader view of the whole system, but for practical purposes this is broken down into several queues, typically associated with the state of the process. Processes in memory and ready to execute are placed in the {\bf ready queue}.  Processes waiting on a particular I/O device are on the {\bf device queue}. When a process is selected for execution it is {\bf dispatched} by an operating system component known as the {\bf dispatcher}. Once a process is dispatched it can issue an I/O request and get placed on the device queue, create a new sub-process and wait around for its termination, execute some instructions on its own data or be forcibly removed from the CPU to the ready queue as the result of an interrupt. 
\subsection{Schedulers}
A process will move between various queues over its lifetime. This is managed by a number of schedulers. The {\bf process scheduler} selects a process from a pool of candidates and loads them into memory for execution. The {\bf CPU scheduler} selects processes from memory and allocates access to the CPU for a period of time. Each scheduler will implement one or more algorithms, each of which is chosen based on a set of desired criteria. The simplest objective for a process scheduler is to ensure a good balance between {\bf I/O bound} and {\bf CPU bound} processes. At the CPU level, the priority is typically to maximize the utilization of the CPU. 
\subsection{Context Switch}
When an interrupt causes the operating system to change the currently executing task to some other task it is necessary to execute some management tasks. In essence, the current {\bf context} is defined by the contents of the process control block. When the process control block is written and saved, either to backing store or memory, it is known as a context switch. Context switching is totally overhead and a very important cost to consider in a multi-programming environment. This cost is comprised of memory write cycles, and possibly disk write cycles to save the state of the process control block. However, emptying of the CPU pipeline and likely invalidation of multiple levels of CPU cache must also be factored into this cost. 
\subsection{Process Creation}
A {\bf tree of processes} is created by a some process creating a child process and, in turn, that child process creating further children. Upon creation of a process, it is assigned a unique {\bf process identifier}. Sub-processes can be restricted to a subset of the parents resources and can also share state and resources with its parent. A parent process may execute {\bf concurrently} with its children, or it may hang around and wait for its children to terminate before exiting. A child process duplicates the parents' process, sharing its address space. 
\subsubsection{Examples}
In Linux the {\bf fork} system call will create the new process. After this call is invoked both processes continue execution. The return type of the fork call is an it integer, which will be used within the program to understand which process is currently executing. If this value is zero, we are currently in the child process. Figure \cite{fork} illustrates an example. The {\bf exclp} system call will replace the currently executing process image with a new image. In this case, the forked child process executes the Linux {\bf ls} command which will list the files in the current directory. The parent process simply waits until the forked child completes and exits. The listing is shown in figure \ref{linuxfork}

\begin{figure}
\caption{Linux Forking \cite{OSCONCEPTS}}
\begin{center}
\lstinputlisting[language=c]{../listings/linux_fork.c}
\label{linuxfork}
\end{center}
\end{figure}
The analogous system call on Windows is {\it CreateProcess}. It is pretty much similar in all respects except that it requires the loading of a specified program into the address space of the child process, whereas this is not explicitly required with linux. The listing in figure \ref{windowscreateprocess} shows how this is done.  

\begin{figure}
\caption{Windows CreateProcess\cite{OSCONCEPTS}}
\begin{center}
\lstinputlisting[language=c]{../listings/create_process.cpp}
\label{windowscreateprocess}
\end{center}
\end{figure}

\subsection{Process Termination}
A program will execute when it execute its last statement and invokes the {\it exit} system call. At this point a process may return some value to its parent. All resources allocated to the process are de-allocated by the operation system. A child may be terminated if it has exceeded its usage of resources, if the task is no longer required and killed by a user or if it's parent process is terminating. 
\section{Inter-Process Communication}
Processes being executed concurrently by the OS may be either {\bf independent} or {\bf co-operating}. There are a number of advantages to processes co-operating to get a specific set of work done. Files, or other data may be shared between processes. This is particularly useful if retrieving the data in the first instance is an expensive operation. Breaking processes into sub-process can assist in speed of execution, particularly if the executing program lends itself to parallelism. For example, a web-crawler process that is responsible for downloading and parsing web-pages could share the same program text, but differ in the URL as a parameter. Retrieving a web-page is an I/O intensive operation, which involves some waiting, so even at the CPU level there is some benefit to have two of the same processes waiting on I/O from two different requests in parallel.  Another benefit is modularity of design, which facilitates simplicity of understanding and development for the programmer. However, in order to accomplish this communication, the operating system must facilitate the programmer via a system call. 
\subsection{Shared Memory}
Process that wish to communicate may establish a region of shared memory that resides in the address space of the initializing process. Other processes wishing to communicate will attach to this address space. This requires the process to circumvent the OS restriction that processes cannot reference the address space of other processes. Therefore the operating system must facilitate this interaction by means of system call. The Linux system call that facilitates this is {\bf shmget}. A good use case for shared memory is where a producer/consumer relationship exists between the processes. A simple bounded, or unbounded, buffer is constructed between the two processes using a shared memory space. Figure \ref{posix_sm} shows a small application that uses shared memory on Linux. 
\begin{figure}
\caption{POSIX Shared Memory Example \cite{OSCONCEPTS}}
\begin{center}
\lstinputlisting[language=c]{../listings/posix_sm.c}
\label{posix_sm}
\end{center}
\end{figure}
\subsection{Message Passing}
In order to avoid sharing an explicit memory address space, a process can leverage message passing. This is particularly useful in the cases where sharing of an address spaces is not possible, such as when processes are located on different machines. There are two operations, {\bf send(message)} and {\bf receive(message)}. Message structure and size can be defined by the processes that are communicating, but can vary depending on implementation. In order for processes to communicate at least a logical communication link must exist between the processes. 
\subsubsection{Direct or Indirect}
For direct communication, processes much know each others identity. This is known as {\bf symmetric addressing}.  Exactly one link can then be established between a pair of processes, with a single link associated with exactly two processes. Conversely, for indirect or asymmetric addressing, the receive end of the communication pair does not need to know the identity of the link from which it is accepting a message. To facilitate this, messages are sent to {\bf ports} or {\bf mailboxes}. The link between processes is only established if they actually share a mailbox. In the case of indirect communication, a link may be associated with more than two processes and multiple links may exist between two processes.
\subsubsection{Synchronization of Communication} 
Message passing may be {\bf blocking} or {\bf non-blocking} also referred to as {\bf synchronous} or {\bf asynchronous}. A {\bf blocking send} will cause the sending process to pause until the message is either received by the target process, or in the target mailbox. A non-blocking send will simply {\bf fire and forget} or in other words the process will not hang around and wait for confirmation that the message has appeared in the target mailbox. Similarly, a {\bf blocking receive} will wait for a message to be received  before continuing, with a {\bf non blocking receive} the converse. There are advantages to each in different situations. For example, a thread of execution on a web-browser will execute a blocking receive until some web browser requests a web page. If we are uploading a file over TCP, we will execute a blocking send, and ensure the whole file has been uploaded correctly before continuing. 
\subsubsection{Buffering}
Indirect and direct communication systems may include a buffer between the sender and the receiver. In general terms you will hear this referred to as a queue. If the {\bf capacity} of the queue is zero then the sender requires a blocking send. If there is a non-zero queue size, and the queue is full, then a blocking send may also be necessary. If the queue is unbounded, there is no need to block, as the queue will always accept messages that are sent. This is useful in situations where we have a finite amount of capacity, but the queueing strategy is not concerned with over-writing messages that were previously sent. 
\subsection{Example - Windows XP}
Windows XP supports multiple operating subsystems that communicate with applications via message passing. Applications are considered clients of the sub-system services. A {\bf local procedure call} is executed over a {\bf port} that is established between the service and the application. These connection ports are visible to all processes. The function of a port is to provide a destination to which the client application can get a {\bf handle} and send a connection request. After the request has been acknowledged by Windows, the server creates two private communication ports and returns one handle to the client. The client and the server are now free to use the ports to send messages or {\bf call-backs} and listen for replies. Small messages which need to be smaller than 256 bytes are sent through the queue that exists between the application and the server. A {\bf section object} may be used by a region of shared memory to pass larger messages between processes. Figure \ref{winxpmsg} shows this process diagrammatically. 
\begin{figure}
\caption{Windows XP Message Passing Facility \cite{OSCONCEPTS}}
\begin{center}
\includegraphics[scale=0.45]{../images/windows-xp-message-passing.png}
\label{winxpmsg}
\end{center}
\end{figure}
\subsection{Client/Server Communication}
The final word in this article is left for a very common approach to communication between processes over a network. In a similar vein to the Windows XP service discussed above {\bf servers} will listen on ports that they expose to {\bf clients}. In one approach, unique pairs of {\bf sockets} enable a communication channel between machines. These channels can be {\bf connection oriented} or {\bf connectionless}. Typically, they are conducted over the TCP/IP stack, which is a layer of libraries that define how communication is conducted over the network. For connectionless sockets, we can use UDP, or {\bf uniform datagram protocol}. There are now explicit connections between machines, and some intermediary machines will be involved in helping out with message delivery. On top of UDP, we also have TCP, or {\bf transmission control protocol}. This will use UDP under the hood, but add in some functionality that provides some guarantees on delivery, as well as error checking.
\newline\newline
Moving further up in the layers, we also have {remote procedure call} or RPC. The aim of this facility is to allow a program to {\bf invoke} a procedure on another machine in a similar way to a call that it would make locally. In practice it's not quite as easy. Data that is passed into remote method calls must at some stage be {\bf martialled} on the wire, and mechanisms must be agreed for this an other criteria. 
\newline\newline
We will discuss this in much more detail in our distributed systems module, for now just note this as a form of inter process communication. 
\bibliography{../biblio/techfundamentals.bib}{}
\bibliographystyle{plain}
\begin{center}
{\small \copyright  David Lynch 2012. Do not reproduce without written permission.}
\end{center}
\end{document}
